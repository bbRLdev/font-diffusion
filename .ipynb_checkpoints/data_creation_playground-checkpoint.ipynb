{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation. Run during first time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import csv\n",
    "from fontpreview import FontPreview\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "import shutil\n",
    "import uuid\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, Image\n",
    "from fontTools.ttLib import TTFont\n",
    "from fontTools.unicode import Unicode\n",
    "import random\n",
    "\n",
    "\n",
    "def has_glyph(font, glyph):\n",
    "    for table in font['cmap'].tables:\n",
    "        if ord(glyph) in table.cmap.keys():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#For a given font file, create the alphabet and the numbers 0-9\n",
    "def create_alphabet(font_file, image_folder):\n",
    "    font = FontPreview(font_file)\n",
    "    ttf_font = TTFont(font_file)\n",
    "    font_name = font.font.getname()[0]\n",
    "    included_chars = []\n",
    "    for char in string.ascii_letters:\n",
    "        if has_glyph(ttf_font, char):\n",
    "            included_chars.append(char)\n",
    "    for char in string.digits:\n",
    "        if has_glyph(ttf_font, char):\n",
    "            included_chars.append(char)\n",
    "    split_folder = 'train'\n",
    "    if len(included_chars) != 62:\n",
    "        split_folder = 'test'\n",
    "        \n",
    "        \n",
    "    save_path = os.path.join(image_folder, split_folder, font_name)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for char in included_chars:\n",
    "        font.font_text = char\n",
    "        font.bg_color = (0, 0, 0)  # white BG\n",
    "        font.dimension = (512, 512)  # Dimension consistent with the default resolution for diffusion models\n",
    "        font.fg_color = (255, 255, 255)  # Letter color\n",
    "        font.set_font_size(300)  # font size ~ 300 pixels\n",
    "        font.set_text_position('center')  # center placement\n",
    "        if char in string.ascii_lowercase:\n",
    "            image_file_name = 'lower_' + char + '.jpg'\n",
    "        elif char in string.ascii_uppercase:\n",
    "            image_file_name = 'upper_' + char + '.jpg'\n",
    "        else:\n",
    "            image_file_name = char + '.jpg'\n",
    "        font.save(os.path.join(save_path, image_file_name))\n",
    "\n",
    "def create_alphabet_for_each_ttf():\n",
    "    TTF_DIR = os.path.join(os.path.abspath(os.getcwd()), 'ttf-files')\n",
    "    IMG_DIR = os.path.join(os.path.abspath(os.getcwd()), 'font-images')\n",
    "    if not os.path.exists(IMG_DIR):\n",
    "        os.mkdir(IMG_DIR)\n",
    "    fnames = os.listdir(TTF_DIR)\n",
    "\n",
    "    for fname in tqdm(fnames):\n",
    "        TTF_PATH = os.path.join(TTF_DIR, fname)\n",
    "        create_alphabet(TTF_PATH, IMG_DIR)\n",
    "\n",
    "    \n",
    "\n",
    "#Uses pandas to read through the CSV from sheets without the need of constantly redownloading\n",
    "def get_font_ttfs():\n",
    "    # Read the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv('font_dataset.csv')\n",
    "    # Create data folder if it does not exist\n",
    "    if not os.path.exists('ttf-files'):\n",
    "        os.makedirs('ttf-files')\n",
    "    # Loop through each row of the DataFrame\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        # Get the link and filename for the current row\n",
    "        link = row['Link']\n",
    "        filename = row['Filename']\n",
    "        if os.path.exists(os.path.join('ttf-files', filename)):\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        # Download the zip file from the link\n",
    "        response = requests.get(link, stream=True)\n",
    "        with open('temp.zip', 'wb') as temp_file:\n",
    "            shutil.copyfileobj(response.raw, temp_file)\n",
    "        del response\n",
    "        \n",
    "        # Unzip the downloaded file\n",
    "        with ZipFile('temp.zip', 'r') as zip_file:\n",
    "            zip_file.extract(filename)\n",
    "            \n",
    "        # Move the file to the data folder\n",
    "        source_path = os.path.join(os.getcwd(), filename)\n",
    "        dest_path = os.path.join(os.getcwd(), 'ttf-files', filename)\n",
    "        shutil.move(source_path, dest_path)\n",
    "        \n",
    "        # Remove the temporary zip file\n",
    "        os.remove('temp.zip')\n",
    "\n",
    "\n",
    "#Create the jsonl file and training folder for the images\n",
    "def create_dataset():\n",
    "    FONT_IMAGE_PATH = os.path.join(os.getcwd(), 'font-images')\n",
    "    assert os.path.exists(FONT_IMAGE_PATH)\n",
    "    TTF_PATH = os.path.join(os.getcwd(), 'ttf-files')\n",
    "    assert os.path.exists(TTF_PATH)\n",
    "    CSV_PATH = os.path.join(os.getcwd(), 'font_dataset.csv')\n",
    "\n",
    "    \n",
    "    # Step 1: Initialize the json file\n",
    "    # Step 2: Loop through the Dataframe, for each row the Filename column corresponds to the actual\n",
    "    #         folder name in 'font_images'.\n",
    "    # Step 3: For each image in the respective folder, copy it over to the training folder (renaming it) and add its entry\n",
    "    #         to the jsonl file\n",
    "\n",
    "    #Step 1\n",
    "    json_metadata = []\n",
    "    # if not os.path.exists(training_data_path):\n",
    "    #     os.makedirs(training_data_path)\n",
    "\n",
    "\n",
    "    #Step 2\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    train_dataset = []\n",
    "    test_dataset = []\n",
    "    for idx, row_data in df.iterrows():\n",
    "        ttf_path = os.path.join(TTF_PATH, row_data['Filename'])\n",
    "        font_img_dir = FontPreview(ttf_path).font.getname()[0]\n",
    "        split_folder = 'train'\n",
    "        font_img_dir_path = os.path.join(FONT_IMAGE_PATH, split_folder, font_img_dir)\n",
    "        if not os.path.exists(font_img_dir_path):\n",
    "            split_folder = 'test'\n",
    "            font_img_dir_path = os.path.join(FONT_IMAGE_PATH, split_folder, font_img_dir)\n",
    "        font_img_paths = [os.path.join(font_img_dir_path, fname) for fname in os.listdir(font_img_dir_path)]\n",
    "        random.shuffle(font_img_paths)\n",
    "        included_chars = [cur_img_path.split('/')[-1].split('.')[0] for cur_img_path in font_img_paths]\n",
    "        font_rows = []\n",
    "        for img_path, char in zip(font_img_paths, included_chars):\n",
    "            json_data_row = {\n",
    "                'uniqueId': str(uuid.uuid4()),\n",
    "                'image': img_path,\n",
    "                'ttf_path': ttf_path,\n",
    "                'font_characteristics': row_data['Descriptors'], \n",
    "                'character': char,\n",
    "                'font_properties': {\n",
    "                    'font_weight': row_data['Weight'], \n",
    "                    'rounding': row_data['Courner Rounding'], \n",
    "                    'font_serifs': row_data['Serif'],\n",
    "                    'width': row_data['Width'],\n",
    "                    'capitals': row_data['Capitals'],\n",
    "                    'dynamics': row_data['Dynamics'] \n",
    "                }\n",
    "            }\n",
    "            font_rows.append(json_data_row)\n",
    "        if split_folder == 'train':\n",
    "            train_dataset = train_dataset + font_rows\n",
    "        else:\n",
    "            test_dataset = test_dataset + font_rows\n",
    "    #Create the jsonl file\n",
    "    with open('train-metadata.jsonl', 'w') as f:\n",
    "        for item in train_dataset:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    with open('test-metadata.jsonl', 'w') as f:\n",
    "        for item in test_dataset:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    #get_fonts('font_files', 'font_images')\n",
    "    #create_dataset('font_images', 'font_files', 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home1/08823/msrodlab/.cache/huggingface/datasets/json/default-e4507dd3f6d3ed03/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805676e4cb89474b9200a0e3f1ae02c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67d7d26ce9c4b5aaacc93e527c9a29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home1/08823/msrodlab/.cache/huggingface/datasets/json/default-e4507dd3f6d3ed03/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e3db99d1c5427189d748de843bcc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files={'train': 'train-metadata.jsonl', 'test': 'test-metadata.jsonl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uniqueId': '0bf58952-d77a-4ec5-b7ac-437fc74f992c', 'image': '/work/08823/msrodlab/maverick2/font-diffusion/font-images/train/Rayman 2/upper_L.jpg', 'ttf_path': '/work/08823/msrodlab/maverick2/font-diffusion/ttf-files/Rayman2-regular.ttf', 'font_characteristics': 'chinese restaurant asian ', 'character': 'upper_L', 'font_properties': {'font_weight': 'black', 'rounding': 'rounded', 'font_serifs': 'serif', 'width': 'extended', 'capitals': 'all caps', 'dynamics': 'dynamic'}}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf home1/08823/msrodlab/.cache/huggingface/datasets/json"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
