{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPTokenizer\n",
    "from datasets import load_dataset\n",
    "from datasets import Image as HuggingFaceImage\n",
    "from linformer import Linformer\n",
    "from vit_pytorch.efficient import ViT\n",
    "from dalle2_pytorch.tokenizer import tokenizer\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "\n",
    "def get_tokenizer() -> CLIPTokenizer:\n",
    "    return CLIPTokenizer.from_pretrained('openai/clip-vit-base-patch32')\n",
    "def get_tokenizer2():\n",
    "    return tokenizer\n",
    "def prepare_data(tokenizer):\n",
    "    def add_prompt(example):\n",
    "        props = example['font_properties']\n",
    "        character = example['character']\n",
    "        split = character.split('_')\n",
    "        if len(split) > 1:\n",
    "            character = split[0] + 'case ' + split[1]\n",
    "        else:\n",
    "            character = split[0]\n",
    "        prompt = f\"a {props['font_serifs']} {character} with {props['width']} width {props['rounding']} corners {props['font_weight']} weight and {props['dynamics']} movement with characteristics that can be described by adjectives {example['font_characteristics']}\" \n",
    "        example['prompt'] = prompt\n",
    "        return example\n",
    "    def map_tokens(example):\n",
    "        prompt = example['prompt']\n",
    "        tokens = tokenizer.encode(prompt, padding='max_length', max_length=256)\n",
    "        #tokens = tokenizer.encode(prompt)\n",
    "        example['tokens'] = tokens\n",
    "        return example\n",
    "    dataset = load_dataset('json', data_files={'train':'train-metadata.jsonl', 'test':'test-metadata.jsonl'})\n",
    "    \n",
    "    train_new_column = ['foo'] * len(dataset['train'])\n",
    "    dataset['train'] = dataset['train'].add_column('prompt', train_new_column)\n",
    "    dataset['train'] = dataset['train'].add_column('tokens', train_new_column)\n",
    "    dataset['train'] = dataset['train'].map(add_prompt)\n",
    "    dataset['train'] = dataset['train'].map(map_tokens)\n",
    "    dataset['train'] = dataset['train'].remove_columns(['prompt', 'uniqueId', 'ttf_path', 'font_characteristics', 'font_properties', 'character', 'vit_label'])\n",
    "    dataset['train'] = dataset['train'].cast_column('image', HuggingFaceImage())\n",
    "    dataset['train'] = dataset['train'].with_format('torch')\n",
    "    \n",
    "    test_new_column = ['bar'] * len(dataset['test'])\n",
    "    dataset['test'] = dataset['test'].add_column('prompt', test_new_column)\n",
    "    dataset['test'] = dataset['test'].add_column('tokens', test_new_column)\n",
    "    dataset['test'] = dataset['test'].map(add_prompt)\n",
    "    dataset['test'] = dataset['test'].map(map_tokens)\n",
    "    dataset['test'] = dataset['test'].remove_columns(['prompt', 'uniqueId', 'ttf_path', 'font_characteristics', 'font_properties', 'character', 'vit_label'])\n",
    "    dataset['test'] = dataset['test'].cast_column('image', HuggingFaceImage())\n",
    "    dataset['test'] = dataset['test'].with_format('torch')\n",
    "    return dataset\n",
    "def get_vit_model(image_size: int, patch_size: int, dim: int, depth: int, num_heads: int, k: int, device: str):\n",
    "    sequence_length = (image_size//patch_size)**2 + 1\n",
    "    # for 512x512px image with 32x32px patches: 16x16 + 1 CLS token\n",
    "    efficient_transformer = Linformer(\n",
    "        dim=dim,\n",
    "        seq_len=sequence_length,  \n",
    "        depth=depth,\n",
    "        heads=num_heads,\n",
    "        k=k\n",
    "    )\n",
    "    model = ViT(\n",
    "        dim=dim,\n",
    "        image_size=image_size,\n",
    "        patch_size=patch_size,\n",
    "        num_classes=62,\n",
    "        transformer=efficient_transformer,\n",
    "        channels=1,\n",
    "    )\n",
    "    return model \n",
    "def get_vit(image_size, patch_size, vit_dim, vit_depth, vit_num_heads, k, device, vit_checkpoint_path):\n",
    "    vit = get_vit_model(image_size=image_size, \n",
    "                        patch_size=patch_size, \n",
    "                        dim=vit_dim, \n",
    "                        depth=vit_depth, \n",
    "                        num_heads=vit_num_heads, \n",
    "                        k=k, \n",
    "                        device=device)\n",
    "    if vit_checkpoint_path != None:\n",
    "        vit_checkpoint = torch.load(vit_checkpoint_path)\n",
    "        vit.load_state_dict(vit_checkpoint['model_state_dict'])\n",
    "        print('Loaded ViT model from checkpoint:', vit_checkpoint_path)\n",
    "    return vit\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Decoder/Prior: OpenAI CLIP "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/rinat/.cache/huggingface/datasets/json/default-1e07ea3eabca7683/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad8040ade814a43ad6da51721cbe564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\rinat\\.cache\\huggingface\\datasets\\json\\default-1e07ea3eabca7683\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-54018895e1b774e9.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rinat\\.cache\\huggingface\\datasets\\json\\default-1e07ea3eabca7683\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-8115de56d8df858f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rinat\\.cache\\huggingface\\datasets\\json\\default-1e07ea3eabca7683\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-2ad7280546491b5e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rinat\\.cache\\huggingface\\datasets\\json\\default-1e07ea3eabca7683\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-5c61c0fc59a2958d.arrow\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "dataset = prepare_data(get_tokenizer())\n",
    "#images_tensor = dataset['train'][0:2]['image']\n",
    "#texts_tensor = dataset['train'][0:2]['tokens']\n",
    "\n",
    "\n",
    "#images_tensor = images_tensor.permute(0, 3, 1, 2)\n",
    "#images_tensor = images_tensor.float()\n",
    "\n",
    "#print(images_tensor.shape)\n",
    "#print(texts_tensor.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12090 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  0\n",
      "Loss: 1.0043487548828125\n",
      "Batch  0\n",
      "Loss: 1.0021426677703857\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/12090 [01:02<1:51:43,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  100\n",
      "Loss: 0.6581845879554749\n",
      "Batch  100\n",
      "Loss: 1.0761290788650513\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 200/12090 [02:01<1:39:16,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  200\n",
      "Loss: 1.4763939380645752\n",
      "Batch  200\n",
      "Loss: 0.6246916055679321\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 300/12090 [03:02<1:51:20,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  300\n",
      "Loss: 2.0950543880462646\n",
      "Batch  300\n",
      "Loss: 0.6427910327911377\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12090 [04:02<1:43:36,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  400\n",
      "Loss: 0.44975772500038147\n",
      "Batch  400\n",
      "Loss: 0.9298602342605591\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 500/12090 [04:59<1:42:20,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  500\n",
      "Loss: 0.574957549571991\n",
      "Batch  500\n",
      "Loss: 0.17286932468414307\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 600/12090 [06:00<1:41:16,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  600\n",
      "Loss: 0.3430556654930115\n",
      "Batch  600\n",
      "Loss: 0.6291264891624451\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 700/12090 [06:58<1:43:21,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  700\n",
      "Loss: 0.07377719134092331\n",
      "Batch  700\n",
      "Loss: 0.03940613567829132\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 800/12090 [08:00<1:46:02,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  800\n",
      "Loss: 0.14477425813674927\n",
      "Batch  800\n",
      "Loss: 0.0780532956123352\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 900/12090 [08:54<1:28:35,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  900\n",
      "Loss: nan\n",
      "Batch  900\n",
      "Loss: nan\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1000/12090 [09:52<1:49:24,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  1000\n",
      "Loss: nan\n",
      "Batch  1000\n",
      "Loss: nan\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1100/12090 [10:50<1:29:03,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  1100\n",
      "Loss: nan\n",
      "Batch  1100\n",
      "Loss: nan\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 1200/12090 [11:43<1:27:22,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  1200\n",
      "Loss: nan\n",
      "Batch  1200\n",
      "Loss: nan\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1300/12090 [12:41<1:48:11,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  1300\n",
      "Loss: nan\n",
      "Batch  1300\n",
      "Loss: nan\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1400/12090 [13:39<1:40:19,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  1400\n",
      "Loss: nan\n",
      "Batch  1400\n",
      "Loss: nan\n",
      "Saving decoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1469/12090 [14:22<1:43:59,  1.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m unet_number \u001b[39min\u001b[39;00m (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m):\n\u001b[1;32m---> 81\u001b[0m     loss \u001b[39m=\u001b[39m decoder_trainer(\n\u001b[0;32m     82\u001b[0m         img,\n\u001b[0;32m     83\u001b[0m         text \u001b[39m=\u001b[39;49m emb,\n\u001b[0;32m     84\u001b[0m         unet_number \u001b[39m=\u001b[39;49m unet_number, \u001b[39m# which unet to train on\u001b[39;49;00m\n\u001b[0;32m     85\u001b[0m         max_batch_size \u001b[39m=\u001b[39;49m \u001b[39m4\u001b[39;49m         \u001b[39m# gradient accumulation - this sets the maximum batch size in which to do forward and backwards pass - for this example 32 / 4 == 8 times\u001b[39;49;00m\n\u001b[0;32m     86\u001b[0m     )\n\u001b[0;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m print_loss_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     89\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBatch \u001b[39m\u001b[39m'\u001b[39m, i)\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\dalle2_pytorch\\trainer.py:107\u001b[0m, in \u001b[0;36mcast_torch_tensor.<locals>.inner\u001b[1;34m(model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m args, kwargs_values \u001b[39m=\u001b[39m all_args[:split_kwargs_index], all_args[split_kwargs_index:]\n\u001b[0;32m    105\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mtuple\u001b[39m(\u001b[39mzip\u001b[39m(kwargs_keys, kwargs_values)))\n\u001b[1;32m--> 107\u001b[0m out \u001b[39m=\u001b[39m fn(model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\dalle2_pytorch\\trainer.py:723\u001b[0m, in \u001b[0;36mDecoderTrainer.forward\u001b[1;34m(self, unet_number, max_batch_size, return_lowres_cond_image, *args, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[39mfor\u001b[39;00m chunk_size_frac, (chunked_args, chunked_kwargs) \u001b[39min\u001b[39;00m split_args_and_kwargs(\u001b[39m*\u001b[39margs, split_size \u001b[39m=\u001b[39m max_batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    722\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mautocast():\n\u001b[1;32m--> 723\u001b[0m         loss_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(\u001b[39m*\u001b[39mchunked_args, unet_number \u001b[39m=\u001b[39m unet_number, return_lowres_cond_image\u001b[39m=\u001b[39mreturn_lowres_cond_image, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mchunked_kwargs)\n\u001b[0;32m    724\u001b[0m         \u001b[39m# loss_obj may be a tuple with loss and cond_image\u001b[39;00m\n\u001b[0;32m    725\u001b[0m         \u001b[39mif\u001b[39;00m return_lowres_cond_image:\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\dalle2_pytorch\\dalle2_pytorch.py:3245\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, image, text, image_embed, text_encodings, unet_number, return_lowres_cond_image)\u001b[0m\n\u001b[0;32m   3243\u001b[0m \u001b[39mif\u001b[39;00m exists(text) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m exists(text_encodings) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munconditional:\n\u001b[0;32m   3244\u001b[0m     \u001b[39massert\u001b[39;00m exists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclip), \u001b[39m'\u001b[39m\u001b[39mif you are passing in raw text, you need to supply `clip` to the decoder\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m-> 3245\u001b[0m     _, text_encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclip\u001b[39m.\u001b[39;49membed_text(text)\n\u001b[0;32m   3247\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcondition_on_text_encodings \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m exists(text_encodings)), \u001b[39m'\u001b[39m\u001b[39mtext or text encodings must be passed into decoder if specified\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   3248\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcondition_on_text_encodings \u001b[39mand\u001b[39;00m exists(text_encodings)), \u001b[39m'\u001b[39m\u001b[39mdecoder specified not to be conditioned on text, yet it is presented\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\dalle2_pytorch\\dalle2_pytorch.py:366\u001b[0m, in \u001b[0;36mOpenAIClipAdapter.embed_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    363\u001b[0m text_mask \u001b[39m=\u001b[39m text_mask \u001b[39m&\u001b[39m (text \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m    364\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcleared\n\u001b[1;32m--> 366\u001b[0m text_embed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclip\u001b[39m.\u001b[39;49mencode_text(text)\n\u001b[0;32m    367\u001b[0m text_encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_encodings\n\u001b[0;32m    368\u001b[0m text_encodings \u001b[39m=\u001b[39m text_encodings\u001b[39m.\u001b[39mmasked_fill(\u001b[39m~\u001b[39mtext_mask[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mNone\u001b[39;00m], \u001b[39m0.\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\clip\\model.py:350\u001b[0m, in \u001b[0;36mCLIP.encode_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    348\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_embedding[:n_ctx]\u001b[39m.\u001b[39mtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    349\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# NLD -> LND\u001b[39;00m\n\u001b[1;32m--> 350\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(x)\n\u001b[0;32m    351\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# LND -> NLD\u001b[39;00m\n\u001b[0;32m    352\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_final(x)\u001b[39m.\u001b[39mtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\clip\\model.py:204\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresblocks(x)\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\clip\\model.py:192\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    191\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(x))\n\u001b[1;32m--> 192\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln_2(x))\n\u001b[0;32m    193\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rinat\\anaconda3\\envs\\font_diffusion\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dalle2_pytorch import DALLE2, Unet, Decoder, OpenAIClipAdapter\n",
    "from dalle2_pytorch import DecoderTrainer\n",
    "# openai pretrained clip - defaults to ViT-B/32\n",
    "n_epochs = 1\n",
    "print_loss_every = 500\n",
    "clip = OpenAIClipAdapter()\n",
    "\n",
    "# decoder (with unet)\n",
    "\n",
    "unet1 = Unet(\n",
    "    dim = 128,\n",
    "    image_embed_dim = 512,\n",
    "    cond_dim = 128,\n",
    "    channels = 3,\n",
    "    dim_mults=(1, 2, 4, 8),\n",
    "    text_embed_dim = 512,\n",
    "    cond_on_text_encodings = True  # set to True for any unets that need to be conditioned on text encodings (ex. first unet in cascade)\n",
    ").cuda()\n",
    "\n",
    "unet2 = Unet(\n",
    "    dim = 16,\n",
    "    image_embed_dim = 512,\n",
    "    cond_dim = 128,\n",
    "    channels = 3,\n",
    "    dim_mults = (1, 2, 4, 8, 16)\n",
    ").cuda()\n",
    "\n",
    "decoder = Decoder(\n",
    "    unet = (unet1, unet2),\n",
    "    image_sizes = (128, 256),\n",
    "    clip = clip,\n",
    "    timesteps = 1000,\n",
    "    sample_timesteps = (250, 27),\n",
    "    image_cond_drop_prob = 0.1,\n",
    "    text_cond_drop_prob = 0.5\n",
    ").cuda()\n",
    "\n",
    "decoder_trainer = DecoderTrainer(\n",
    "    decoder,\n",
    "    lr = 1e-5,\n",
    "    wd = 1e-2,\n",
    "    ema_beta = 0.99,\n",
    "    ema_update_after_step = 1000,\n",
    "    ema_update_every = 10,\n",
    ")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print('Epoch: ', epoch)\n",
    "    u1_loss = 0 \n",
    "    u2_loss = 0\n",
    "\n",
    "    for i, data in enumerate(tqdm(dataset['train'])):\n",
    "        img, emb = data['image'], data['tokens'] \n",
    "        img = img.unsqueeze(0)\n",
    "        emb = emb.unsqueeze(0)\n",
    "        img = img.permute(0, 3, 1, 2)\n",
    "        img = img.float()\n",
    "\n",
    "        for unet_number in (1, 2):\n",
    "            loss = decoder_trainer(\n",
    "                img,\n",
    "                text = emb,\n",
    "                unet_number = unet_number, # which unet to train on\n",
    "                max_batch_size = 4         # gradient accumulation - this sets the maximum batch size in which to do forward and backwards pass - for this example 32 / 4 == 8 times\n",
    "            )\n",
    "\n",
    "            if i % print_loss_every == 0:\n",
    "                print('Batch ', i)\n",
    "                print('Loss:', loss)\n",
    "            decoder_trainer.update(unet_number)\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print('Saving decoder model...')\n",
    "            decoder_trainer.save(\"best_decoder.pth\")\n",
    "print('Saving last decoder')\n",
    "decoder_trainer.save(\"last_decoder.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12090 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  0\n",
      "Loss: 1.3394761085510254\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 99/12090 [00:10<17:44, 11.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 200/12090 [00:20<17:52, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 300/12090 [00:30<17:37, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12090 [00:41<18:08, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 499/12090 [00:52<18:24, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  500\n",
      "Loss: 0.0503176786005497\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 600/12090 [01:03<17:56, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 700/12090 [01:13<18:04, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 799/12090 [01:24<18:02, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 899/12090 [01:34<16:44, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 999/12090 [01:45<17:25, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  1000\n",
      "Loss: 0.040028274059295654\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1099/12090 [01:55<16:47, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 1199/12090 [02:06<16:30, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1299/12090 [02:16<16:39, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1400/12090 [02:27<16:44, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1499/12090 [02:38<16:51, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  1500\n",
      "Loss: 0.012066573835909367\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1599/12090 [02:49<17:25, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1699/12090 [03:00<16:44, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1799/12090 [03:10<16:18, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1899/12090 [03:21<16:06, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1999/12090 [03:31<15:25, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  2000\n",
      "Loss: 0.020679708570241928\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2099/12090 [03:42<15:07, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2199/12090 [03:52<15:06, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 2299/12090 [04:03<15:17, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 2301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 2400/12090 [04:14<15:48, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2500/12090 [04:25<14:45, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  2500\n",
      "Loss: 0.05247374624013901\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 2501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 2599/12090 [04:35<14:47, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 2601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2699/12090 [04:46<14:13, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 2701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2799/12090 [04:56<13:56, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2899/12090 [05:07<14:20, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 2901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 3000/12090 [05:18<13:50, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  3000\n",
      "Loss: 0.03938603028655052\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 3001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 3099/12090 [05:28<14:41, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 3199/12090 [05:39<14:14, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 3201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3299/12090 [05:49<13:16, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 3399/12090 [05:59<13:05, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 3401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 3500/12090 [06:10<12:42, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  3500\n",
      "Loss: 0.08618474006652832\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 3600/12090 [06:20<12:38, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 3601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3700/12090 [06:31<12:28, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 3701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 3799/12090 [06:41<13:06, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3899/12090 [06:51<12:39, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3999/12090 [07:02<12:00, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  4000\n",
      "Loss: 0.041893236339092255\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 4001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 4100/12090 [07:12<11:41, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 4101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 4199/12090 [07:23<11:37, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 4201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 4300/12090 [07:33<11:17, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 4301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4400/12090 [07:44<12:10, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 4401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 4499/12090 [07:54<11:08, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  4500\n",
      "Loss: 0.057119447737932205\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 4501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 4599/12090 [08:04<10:54, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 4601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 4699/12090 [08:14<11:27, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 4701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 4799/12090 [08:25<11:12, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 4801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4900/12090 [08:35<10:29, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 4901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 5000/12090 [08:46<11:07, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  5000\n",
      "Loss: 0.03016403131186962\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5100/12090 [08:56<10:44, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 5200/12090 [09:07<10:06, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 5201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 5300/12090 [09:17<10:06, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 5400/12090 [09:28<10:12, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 5401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5499/12090 [09:38<09:58, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  5500\n",
      "Loss: 0.03418148681521416\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 5600/12090 [09:48<09:47, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 5699/12090 [09:58<09:25, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 5799/12090 [10:09<10:04, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 5801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 5899/12090 [10:19<09:16, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 5999/12090 [10:30<08:58, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  6000\n",
      "Loss: 0.02560434862971306\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6099/12090 [10:40<09:03, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 6101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 6199/12090 [10:50<08:46, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 6300/12090 [11:01<09:09, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 6301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 6400/12090 [11:11<08:47, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 6499/12090 [11:22<08:09, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  6500\n",
      "Loss: 0.011082777753472328\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 6599/12090 [11:32<08:21, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 6699/12090 [11:42<07:59, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 6701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 6799/12090 [11:53<07:42, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 6801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 6899/12090 [12:03<07:36, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 6901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7000/12090 [12:14<07:35, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  7000\n",
      "Loss: 0.00894743762910366\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 7001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 7099/12090 [12:24<08:29,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 7101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 7200/12090 [12:35<07:14, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 7299/12090 [12:46<07:22, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 7400/12090 [12:56<07:29, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 7401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 7500/12090 [13:07<06:45, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  7500\n",
      "Loss: 0.04396612197160721\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 7501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 7600/12090 [13:17<06:46, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 7601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 7700/12090 [13:28<06:55, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 7701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 7800/12090 [13:39<06:51, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 7801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 7899/12090 [13:49<06:27, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 7901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 8000/12090 [14:00<06:39, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  8000\n",
      "Loss: 0.04007840156555176\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8100/12090 [14:10<05:49, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 8101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 8200/12090 [14:20<06:01, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 8201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 8300/12090 [14:30<05:44, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 8301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 8400/12090 [14:41<05:22, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 8401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 8500/12090 [14:51<05:22, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  8500\n",
      "Loss: 0.024765610694885254\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 8599/12090 [15:01<05:17, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 8601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 8699/12090 [15:12<05:12, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 8701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8800/12090 [15:22<04:54, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 8899/12090 [15:32<05:08, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 8999/12090 [15:43<04:35, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  9000\n",
      "Loss: 0.0305095873773098\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 9001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9099/12090 [15:53<04:21, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 9101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 9200/12090 [16:04<04:14, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 9300/12090 [16:14<04:21, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 9301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 9399/12090 [16:25<04:00, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 9401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 9500/12090 [16:35<03:49, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  9500\n",
      "Loss: 0.03989984840154648\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 9501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 9599/12090 [16:46<03:53, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 9601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 9699/12090 [16:56<03:49, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 9799/12090 [17:07<03:34, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9900/12090 [17:17<03:11, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 9999/12090 [17:28<03:03, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  10000\n",
      "Loss: 0.024997321888804436\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 10001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 10099/12090 [17:38<02:57, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 10101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 10199/12090 [17:49<02:57, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 10201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 10299/12090 [17:59<02:41, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 10301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 10400/12090 [18:10<02:32, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 10401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 10500/12090 [18:20<02:29, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  10500\n",
      "Loss: 0.06083837151527405\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 10501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 10599/12090 [18:30<02:15, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 10601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 10699/12090 [18:41<02:06, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 10701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 10799/12090 [18:51<01:59, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 10801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 10899/12090 [19:01<01:49, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 10901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10999/12090 [19:12<01:41, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  11000\n",
      "Loss: 0.017904827371239662\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 11001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11099/12090 [19:23<01:33, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 11101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 11199/12090 [19:33<01:21, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 11201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 11300/12090 [19:44<01:11, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 11301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 11400/12090 [19:54<01:01, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 11401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 11499/12090 [20:05<00:54, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  11500\n",
      "Loss: 0.022313546389341354\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 11501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 11600/12090 [20:15<00:45, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 11601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 11700/12090 [20:26<00:36, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 11701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 11800/12090 [20:36<00:27, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 11801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 11900/12090 [20:47<00:16, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prior model...\n",
      "Saving checkpoint at step: 11901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 12000/12090 [20:57<00:08, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  12000\n",
      "Loss: 0.022122971713542938\n",
      "Saving prior model...\n",
      "Saving checkpoint at step: 12001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12090/12090 [21:07<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving last prior model\n",
      "Saving checkpoint at step: 12090\n"
     ]
    }
   ],
   "source": [
    "#### Train the Prior \n",
    "from dalle2_pytorch import DiffusionPrior, DiffusionPriorNetwork, DiffusionPriorTrainer\n",
    "from dalle2_pytorch import OpenAIClipAdapter\n",
    "\n",
    "n_epochs = 1\n",
    "print_loss_every = 500\n",
    "\n",
    "clip = OpenAIClipAdapter()\n",
    "\n",
    "prior_network = DiffusionPriorNetwork(\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    dim_head = 64,\n",
    "    heads = 8\n",
    ").cuda()\n",
    "\n",
    "diffusion_prior = DiffusionPrior(\n",
    "    net = prior_network,\n",
    "    clip = clip,\n",
    "    timesteps = 100,\n",
    "    cond_drop_prob = 0.2\n",
    ").cuda()\n",
    "\n",
    "diffusion_prior_trainer = DiffusionPriorTrainer(\n",
    "    diffusion_prior,\n",
    "    lr = 1e-5,\n",
    "    wd = 1e-2,\n",
    "    ema_beta = 0.99,\n",
    "    ema_update_after_step = 1000,\n",
    "    ema_update_every = 10,\n",
    ")\n",
    "\n",
    "for i, data in enumerate(tqdm(dataset['train'])):\n",
    "        img, emb = data['image'], data['tokens'] \n",
    "        img = img.unsqueeze(0)\n",
    "        emb = emb.unsqueeze(0)\n",
    "        img = img.permute(0, 3, 1, 2)\n",
    "        img = img.float()\n",
    "\n",
    "        loss = diffusion_prior_trainer(emb, img, max_batch_size = 4)\n",
    "\n",
    "\n",
    "        if i % print_loss_every == 0:\n",
    "            print('Batch ', i)\n",
    "            print('Loss:', loss)\n",
    "        diffusion_prior_trainer.update()\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print('Saving prior model...')\n",
    "            diffusion_prior_trainer.save(\"best_prior.pth\")\n",
    "print('Saving last prior model')\n",
    "diffusion_prior_trainer.save(\"last_prior.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample from the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2889f008ea644aaa9ee51545e077814f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe35b208ed2e457498ae16961f721b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e217ceb0aee4ad68b9549a452623f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cdbce2209c4191bd9be005de7e9c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dalle2_pytorch import DALLE2, Unet, Decoder, OpenAIClipAdapter\n",
    "from dalle2_pytorch import DiffusionPrior, DiffusionPriorNetwork\n",
    "\n",
    "clip = OpenAIClipAdapter()\n",
    "#Load the decoder \n",
    "decoder_path = 'best_decoder.pth'\n",
    "unet1 = Unet(\n",
    "    dim = 128,\n",
    "    image_embed_dim = 512,\n",
    "    cond_dim = 128,\n",
    "    channels = 3,\n",
    "    dim_mults=(1, 2, 4, 8),\n",
    "    text_embed_dim = 512,\n",
    "    cond_on_text_encodings = True  # set to True for any unets that need to be conditioned on text encodings (ex. first unet in cascade)\n",
    ").cuda()\n",
    "\n",
    "unet2 = Unet(\n",
    "    dim = 16,\n",
    "    image_embed_dim = 512,\n",
    "    cond_dim = 128,\n",
    "    channels = 3,\n",
    "    dim_mults = (1, 2, 4, 8, 16)\n",
    ").cuda()\n",
    "\n",
    "decoder = Decoder(\n",
    "    unet = (unet1, unet2),\n",
    "    image_sizes = (128, 256),\n",
    "    clip = clip,\n",
    "    timesteps = 1000,\n",
    "    sample_timesteps = (250, 27),\n",
    "    image_cond_drop_prob = 0.1,\n",
    "    text_cond_drop_prob = 0.5\n",
    ").cuda()\n",
    "\n",
    "decoder_model_state = torch.load(decoder_path, map_location='cpu',)['model']\n",
    "for k in decoder.clip.state_dict().keys():\n",
    "    decoder_model_state[\"clip.\" + k] = decoder.clip.state_dict()[k]\n",
    "\n",
    "decoder.load_state_dict(decoder_model_state, strict=True)\n",
    "\n",
    "#Load the prior \n",
    "prior_network = DiffusionPriorNetwork(\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    dim_head = 64,\n",
    "    heads = 8\n",
    ").cuda()\n",
    "\n",
    "diffusion_prior = DiffusionPrior(\n",
    "    net = prior_network,\n",
    "    clip = clip,\n",
    "    timesteps = 100,\n",
    "    cond_drop_prob = 0.2\n",
    ").cuda()\n",
    "\n",
    "\n",
    "prior_path = 'best_prior.pth'\n",
    "\n",
    "prior_model_state = torch.load(prior_path, map_location='cpu')['model']\n",
    "diffusion_prior.load_state_dict(prior_model_state, strict=True) \n",
    "\n",
    "dalle2 = DALLE2(\n",
    "    prior = diffusion_prior,\n",
    "    decoder = decoder\n",
    ")\n",
    "\n",
    "images = dalle2(\n",
    "    ['A lowercase a which has traits blocky and properties black square sans serif static extended all caps'],\n",
    "    cond_scale = 2. # classifier free guidance strength (> 1 would strengthen the condition)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save image \n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "images = images.squeeze(0)\n",
    "img = ToPILImage()(images)\n",
    "img.show()\n",
    "#save_image(images, 'example_output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAIAAADTED8xAAAA1UlEQVR4nO3BMQEAAADCoPVP7WULoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAGwEtAAHMpTgHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HugginFaceImage - 512 x 512 x 3 \n",
    "#Token legnth - 42\n",
    "\n",
    "#Required format: \n",
    "#Image: (B, C, W, H) ~ channels: 3 , W,H: 512 \n",
    "#Text: (B, T)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "font_diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
