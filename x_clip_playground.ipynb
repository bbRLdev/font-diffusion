{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "def get_tokenizer() -> CLIPTokenizer:\n",
    "    return CLIPTokenizer.from_pretrained('openai/clip-vit-base-patch32')\n",
    "def prepare_data(tokenizer: CLIPTokenizer):\n",
    "    def add_prompt(example):\n",
    "        props = example['font_properties']\n",
    "        character = example['character']\n",
    "        split = character.split('_')\n",
    "        if len(split) > 1:\n",
    "            character = split[0] + 'case ' + split[1]\n",
    "        else:\n",
    "            character = split[0]\n",
    "        prompt = f\"a {props['font_serifs']} {character} with {props['width']} width {props['rounding']} corners {props['font_weight']} weight and {props['dynamics']} movement with characteristics that can be described by adjectives {example['font_characteristics']}\" \n",
    "        example['prompt'] = prompt\n",
    "        return example\n",
    "    def map_tokens(example):\n",
    "        prompt = example['prompt']\n",
    "        tokens = tokenizer.encode(prompt)\n",
    "        example['tokens'] = tokens\n",
    "        return example\n",
    "    dataset = load_dataset('json', data_files={'train':'train-metadata.jsonl', 'test':'test-metadata.jsonl'})\n",
    "    \n",
    "    train_new_column = ['foo'] * len(dataset['train'])\n",
    "    dataset['train'] = dataset['train'].add_column('prompt', train_new_column)\n",
    "    dataset['train'] = dataset['train'].add_column('tokens', train_new_column)\n",
    "    dataset['train'] = dataset['train'].map(add_prompt)\n",
    "    dataset['train'] = dataset['train'].map(map_tokens)\n",
    "    \n",
    "    test_new_column = ['bar'] * len(dataset['test'])\n",
    "    dataset['test'] = dataset['test'].add_column('prompt', test_new_column)\n",
    "    dataset['test'] = dataset['test'].add_column('tokens', test_new_column)\n",
    "    dataset['test'] = dataset['test'].map(add_prompt)\n",
    "    dataset['test'] = dataset['test'].map(map_tokens)\n",
    "\n",
    "    # dataset['train'] = dataset['train'].map(map_tokens)\n",
    "    # dataset['test'] = dataset['test'].map(map_tokens)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Michael Labarca/.cache/huggingface/datasets/json/default-c772ad4eb6d31de9/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c05d55953c4cdca1dec315114b23b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Michael Labarca\\.cache\\huggingface\\datasets\\json\\default-c772ad4eb6d31de9\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-6c27256c2b0087be.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8267449c664663969f457d32658557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12090 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Michael Labarca\\.cache\\huggingface\\datasets\\json\\default-c772ad4eb6d31de9\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-a1fe57a82fffa92f.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ea93d948434cb5be2a158f7c0faac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_tokenizer = get_tokenizer()\n",
    "dataset = prepare_data(clip_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = dataset['train'].filter(lambda ex: len(ex['tokens']) != 28)\n",
    "unique = set()\n",
    "for ex in filtered:\n",
    "    if len(ex['tokens']) == 35:\n",
    "        print(ex['prompt'])\n",
    "    unique.add(len(ex['tokens']))\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m tokens \u001b[39m=\u001b[39m dataset[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     16\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(tokens, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint)\n\u001b[1;32m---> 17\u001b[0m out \u001b[39m=\u001b[39m model(tokens)\n",
      "File \u001b[1;32mc:\\Users\\Michael Labarca\\.conda\\envs\\font-diffusion\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Michael Labarca\\.conda\\envs\\font-diffusion\\lib\\site-packages\\linformer\\linformer.py:162\u001b[0m, in \u001b[0;36mLinformerLM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    161\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_emb(x)\n\u001b[1;32m--> 162\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_emb(torch\u001b[39m.\u001b[39;49marange(x\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], device\u001b[39m=\u001b[39;49mx\u001b[39m.\u001b[39;49mdevice)) \u001b[39m+\u001b[39m x\n\u001b[0;32m    163\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinformer(x)\n\u001b[0;32m    164\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_logits(x)\n",
      "File \u001b[1;32mc:\\Users\\Michael Labarca\\.conda\\envs\\font-diffusion\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Michael Labarca\\.conda\\envs\\font-diffusion\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32mc:\\Users\\Michael Labarca\\.conda\\envs\\font-diffusion\\lib\\site-packages\\torch\\nn\\functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from linformer import Linformer\n",
    "import torch\n",
    "class LinformerLM(nn.Module):\n",
    "    def __init__(self, num_tokens, dim, seq_len, depth, k = 256, heads = 8, dim_head = None, one_kv_head = False, share_kv = False, reversible = False, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(num_tokens, dim)\n",
    "        self.pos_emb = nn.Embedding(seq_len, dim)\n",
    "        self.linformer = Linformer(dim, seq_len, depth, k = k, heads = heads, dim_head = dim_head,\n",
    "                one_kv_head = one_kv_head, share_kv = share_kv, reversible = reversible, dropout = dropout)\n",
    "        self.to_logits = nn.Linear(dim, num_tokens)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.token_emb(x)\n",
    "        print(x)\n",
    "        x = self.pos_emb(torch.arange(x.shape[1], device=x.device)) + x\n",
    "        x = self.linformer(x)\n",
    "        out = self.to_logits(x)\n",
    "        return out\n",
    "model = LinformerLM(\n",
    "    num_tokens = 49408,\n",
    "    dim = 256,\n",
    "    seq_len = 28,\n",
    "    depth = 12,\n",
    "    heads = 8,\n",
    "    dim_head = 64,        # be able to set the dimension of each head in multi-head attention\n",
    "    k = 128,               # this is the k that the key/values are projected to along the sequence dimension\n",
    "    one_kv_head = True,    # share one key/value head across all heads\n",
    "    share_kv = False,      # share the same projection for keys and values\n",
    "    reversible = False      # make network reversible, like Reformer\n",
    ")\n",
    "tokens = dataset['train'][0]['tokens']\n",
    "tokens = torch.tensor(tokens, dtype=torch.int)\n",
    "out = model(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linformer import LinformerLM\n",
    "model = LinformerLM(\n",
    "    num_tokens = 49408,\n",
    "    dim = 256,\n",
    "    seq_len = 35,\n",
    "    depth = 12,\n",
    "    heads = 8,\n",
    "    dim_head = 64,        # be able to set the dimension of each head in multi-head attention\n",
    "    k = 128,               # this is the k that the key/values are projected to along the sequence dimension\n",
    "    one_kv_head = True,    # share one key/value head across all heads\n",
    "    share_kv = False,      # share the same projection for keys and values\n",
    "    reversible = False      # make network reversible, like Reformer\n",
    ")\n",
    "x = torch.randint(0, 20000, (1, 49408))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "font-diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
