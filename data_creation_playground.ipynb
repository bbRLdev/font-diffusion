{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI-JEVVPUxhQ",
        "outputId": "548bbe3e-42b9-4a07-f874-d57592a44785"
      },
      "outputs": [],
      "source": [
        "from data_creator import get_font_ttfs, create_alphabet_for_each_ttf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6b3ab6c603f4d7dad1b14d8ec2fa3b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "get_font_ttfs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Razing\n",
            "Military Poster\n",
            "JMH Typewriter\n",
            "No Virus\n",
            "Who asks Satan\n",
            "FoieCanape\n",
            "Dunkirk\n",
            "Seagram tfb\n",
            "Babiole\n",
            "OldNewspaperTypes\n",
            "Short Stack\n",
            "Deutsch Gothic\n",
            "LaIzzIerComiC\n",
            "Vogue\n",
            "Espen Comics\n",
            "Mandrake FF\n",
            "The Kids Mraker\n",
            "Canted Comic\n",
            "Ambambo\n",
            "Nexa\n",
            "Blueto\n",
            "Handwriting\n",
            "Rocket Mission\n",
            "a Anti Corona\n",
            "Tabby - Personal Use\n",
            "MiTica\n",
            "gsmfont\n",
            "Akira Expanded\n",
            "Edson_Comics_Bold\n",
            "Riesling\n",
            "LeArchitect\n",
            "Topuz\n",
            "Coyotris Comic\n",
            "Indernik_Charcoal\n",
            "Nathaniel-19\n",
            "Ducky\n",
            "Verve\n",
            "Asteristico\n",
            "armfight\n",
            "Koshari\n",
            "Onion Rocks\n",
            "Mulled Wine Season\n",
            "Wash Your Hand\n",
            "Edition\n",
            "WOODCUTTER ARMY (Stencil)\n",
            "Bodoni Fragile\n",
            "OlivesLight\n",
            "ByronRecCon\n",
            "Komikula\n",
            "LT Crafted\n",
            "Fette National Fraktur\n",
            "Sakura Town Demo\n",
            "Knobber\n",
            "DCC - Anatolia Strong\n",
            "Brandon Bromley\n",
            "RetroGaming\n",
            "Couture\n",
            "Mufferaw\n",
            "DCC - Dreamer\n",
            "The Alphabet\n",
            "Mucky Sans\n",
            "QuickAsABunny\n",
            "Comic Note Smooth\n",
            "Ohio Collegiate\n",
            "Alphakind\n",
            "King Arthur Legend\n",
            "Comic Helvetic\n",
            "Spork\n",
            "mie aceh\n",
            "AmazGoDaBold\n",
            "FuturaHandwritten\n",
            "Kaph\n",
            "Monicacomic\n",
            "Rundeck\n",
            "I.F.C. HARDBALL \n",
            "Alex Toth\n",
            "SnapHand\n",
            "Cardigan Titling\n",
            "Polsyh\n",
            "Funiko\n",
            "Pulang\n",
            "Enchanted Land\n",
            "Louis George Cafe Light\n",
            "LT Woodchuck\n",
            "JWerd\n",
            "Mario Party Hudson\n",
            "Comica Regular\n",
            "Pak Kumis\n",
            "a Art Paper\n",
            "Canted FX\n",
            "Nightside Demo\n",
            "Caviar Dreams\n",
            "Brocades Sans\n",
            "Bronkos\n",
            "College\n",
            "Comic Shark\n",
            "Handgoal\n",
            "RUSAK\n",
            "Aaron Sans\n",
            "Palamecia Titling\n",
            "Steiner\n",
            "NewYork\n",
            "Sonic Comics\n",
            "Loded Diper\n",
            "DS-Digital\n",
            "Meonk Plans\n",
            "Childscribble By Reka\n",
            "Gargle\n",
            "Blitz\n",
            "Keep on Truckin\n",
            "Bakso Sapi\n",
            "Coconut House\n",
            "000_INSOMNIAC_COMIC_DIALOGUE\n",
            "Simallos\n",
            "Scholar E\n",
            "OlivessansPimientoLight\n",
            "HD DOODLE\n",
            "Indie Komiks Sketch\n",
            "Brantone\n",
            "Stop Bullying\n",
            "Rondouillard\n",
            "BubbleDub\n",
            "AmateurComic\n",
            "Om Botak\n",
            "a Anggota\n",
            "Smilecomix\n",
            "northern army\n",
            "Gameplay\n",
            "CreatiCredad\n",
            "Virus Killer\n",
            "Designer\n",
            "SUGARE\n",
            "DCC - Anatolia Clasic\n",
            "Si Kancil\n",
            "WetinCaroWant\n",
            "Komika Boo\n",
            "Jersey M54\n",
            "HelvetiHand\n",
            "Hey Haters\n",
            "Roller\n",
            "Widound\n",
            "Tahtelbahir komik\n",
            "Bodo Amat\n",
            "theDood\n",
            "Reshuffle Sans\n",
            "Extended Play\n",
            "Chekharda\n",
            "Carista\n",
            "Ninjos\n",
            "Jreeng\n",
            "Pamit\n",
            "Wanted M54\n",
            "DCC - Scisor\n",
            "I Learn From Wall\n",
            "Komika Parch\n",
            "Space Crusaders\n",
            "Ukulele\n",
            "Bad Comic\n",
            "Kemco Pixel\n",
            "Suburbana\n",
            "Seductive Height (Demo)\n",
            "Burbin Casual NC\n",
            "Gorski\n",
            "TT Ricordi Trial\n",
            "Wolfganger\n",
            "comix-pro-2\n",
            "Loosey Sans\n",
            "Melon hunter\n",
            "Jaya Baru\n",
            "Hard Fox\n",
            "NO NAZIS\n",
            "Ardies\n",
            "Homer Simpson Revised\n",
            "a Abstract Groovy\n",
            "Like Snow\n",
            "Bocah\n",
            "Krunch\n",
            "Azonix\n",
            "Single Sleeve\n",
            "Terav\n",
            "Digital Play St\n",
            "Roboto\n",
            "Invasion2000\n",
            "Octin Prison\n",
            "Help Me\n",
            "Dion\n",
            "Comic Note\n",
            "Stanberry\n",
            "Punishment\n",
            "Smack Typographik\n",
            "Modern Prestige DEMO\n",
            "MBBlockType\n",
            "WOODCUTTER simple font\n",
            "Destink Warp\n",
            "Halfway\n",
            "Seagull Wine\n",
            "Rayman 2\n",
            "Gamejot\n",
            "Kimmun\n",
            "Kaiju Monster__G\n",
            "onthemove\n",
            "Badaga\n",
            "Danger Diabolik\n",
            "TT Backwards Sans Trial\n",
            "Hanstoc Script PERSONAL USE\n",
            "Apasih\n",
            "Nixie One\n",
            "Anime Inept\n"
          ]
        }
      ],
      "source": [
        "create_alphabet_for_each_ttf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "import uuid\n",
        "from fontpreview import FontPreview\n",
        "def create_dataset():\n",
        "    FONT_IMAGE_PATH = os.path.join(os.getcwd(), 'font-images')\n",
        "    assert os.path.exists(FONT_IMAGE_PATH)\n",
        "    TTF_PATH = os.path.join(os.getcwd(), 'ttf-files')\n",
        "    assert os.path.exists(TTF_PATH)\n",
        "    CSV_PATH = os.path.join(os.getcwd(), 'CS395T - CV - Font Dataset - Sheet1.csv')\n",
        "\n",
        "    TTF_FNAMES = os.listdir(TTF_PATH)\n",
        "    TTF_FNAMES.sort()\n",
        "\n",
        "    IMG_DIR_FNAMES = os.listdir(FONT_IMAGE_PATH)\n",
        "    IMG_DIR_FNAMES.sort()\n",
        "    \n",
        "    # Step 1: Initialize the json file\n",
        "    # Step 2: Loop through the Dataframe, for each row the Filename column corresponds to the actual\n",
        "    #         folder name in 'font_images'.\n",
        "    # Step 3: For each image in the respective folder, copy it over to the training folder (renaming it) and add its entry\n",
        "    #         to the jsonl file\n",
        "\n",
        "    #Step 1\n",
        "    json_metadata = []\n",
        "    # if not os.path.exists(training_data_path):\n",
        "    #     os.makedirs(training_data_path)\n",
        "\n",
        "\n",
        "    #Step 2\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "    head = df.head()\n",
        "    \n",
        "    file_name_counter = '0'\n",
        "    idx = 0\n",
        "    json_metadata = []\n",
        "    # d = df{}\n",
        "    for idx, row_data in df.iterrows():\n",
        "        ttf_path = os.path.join(TTF_PATH, row_data['Filename'])\n",
        "        font_img_dir = FontPreview(ttf_path).font.getname()[0]\n",
        "        font_img_dir = os.path.join(FONT_IMAGE_PATH, font_img_dir)\n",
        "        font_img_paths = [os.path.join(font_img_dir, fname) for fname in os.listdir(font_img_dir)]\n",
        "        included_chars = [cur_path.split('/')[-1].split('.')[0] for cur_path in font_img_paths]\n",
        "        json_data_row = {\n",
        "            'uniqueId': str(uuid.uuid4()),\n",
        "            'font_img_paths': font_img_paths,\n",
        "            'ttf_path': ttf_path,\n",
        "            'font_characteristics': row_data['Descriptors'], \n",
        "            'chars': included_chars,\n",
        "            'font_properties': {\n",
        "                'font_weight': row_data['Weight'], \n",
        "                'rounding': row_data['Courner Rounding'], \n",
        "                'font_serifs': row_data['Serif'],\n",
        "                'width': row_data['Width'],\n",
        "                'capitals': row_data['Capitals'],\n",
        "                'dynamics': row_data['Dynamics'] \n",
        "            }\n",
        "        }\n",
        "        json_metadata.append(json_data_row)\n",
        "    #Create the jsonl file\n",
        "    with open('metadata.jsonl', 'w') as f:\n",
        "        for item in json_metadata:\n",
        "            f.write(json.dumps(item) + '\\n')\n",
        "\n",
        "    \n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "create_dataset()\n",
        "# 000 InsomniacOvrLrd Comic Dialogue.ttf\n",
        "# 000 InsomniacOvrLrd Comic Dialogue.ttf"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
